import requests
import json
import time

# Org names (Ù‚Ù„ÙŠÙ„Ø© Ø¹Ø´Ø§Ù† ØªØ¨Ù‚ÙŠ Ø£Ø³Ø±Ø¹)
ORGS = ["kubernetes", "hashicorp", "prometheus", "aws", "openstack", "microsoft"]

# Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ ØµÙØ­Ø§Øª Ù‡Ù†Ø¬ÙŠØ¨Ù‡Ø§ Ù…Ù† ÙƒÙ„ org
MAX_PAGES = 5   # ÙƒÙ„ ØµÙØ­Ø© = 100 repo -> 500 repo Ù„ÙƒÙ„ org

# Ø¹Ø´Ø§Ù† ØªÙ‚Ù„Ù„ÙŠ Ø§Ù„ÙˆÙ‚Øª -> Ù…Ø´ Ù‡Ù†Ø¬ÙŠØ¨ README
INCLUDE_README = False  

# Authentication (Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ GitHub token)
TOKEN = None  # Ø¶ÙŠÙÙŠ Ø§Ù„ØªÙˆÙƒÙŠÙ† Ù‡Ù†Ø§ Ù„Ùˆ Ø¹Ø§ÙŠØ²Ø© ØªØ²ÙˆØ¯ÙŠ Ø§Ù„Ø³Ø±Ø¹Ø©
HEADERS = {"Authorization": f"token {TOKEN}"} if TOKEN else {}

def fetch_repos(org, per_page=100):
    repos = []
    for page in range(1, MAX_PAGES + 1):
        url = f"https://api.github.com/orgs/{org}/repos?per_page={per_page}&page={page}"
        print(f"ğŸ“¡ Fetching: {url}")
        r = requests.get(url, headers=HEADERS)
        if r.status_code != 200:
            print(f"âš ï¸ Failed for {org}, page {page}")
            break
        data = r.json()
        if not data:
            break
        for repo in data:
            repos.append({
                "org": org,
                "name": repo.get("name"),
                "description": repo.get("description") or "No description available",
                "url": repo.get("html_url")
            })
        time.sleep(0.1)  # ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§ØŒ Ø£Ø³Ø±Ø¹
    return repos

def main():
    all_repos = []
    for org in ORGS:
        repos = fetch_repos(org)
        print(f"âœ… {org}: {len(repos)} repos")
        all_repos.extend(repos)

    print(f"ğŸ“¦ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ÙƒÙ„ÙŠ: {len(all_repos)} repos")

    with open("github_repos.json", "w") as f:
        json.dump(all_repos, f, indent=2)

    print("ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¯Ø§ØªØ§ ÙÙŠ github_repos.json")

if __name__ == "__main__":
    main()
